README

Created by M. van Beekveld - mcbeekveld@gmail.com
For any errors / questions, don't hesitate to send me an email

IMPORTANT!!
Keep the google docs up to date! Then we know who generates what and where it is stored. You can find it https://docs.google.com/document/d/1N1yetfbXXnAqNb1CIT-ajIKh1EQW2GB8N4Z9HrMAREQ/edit?usp=sharing

Usage:
1. Download and install Madgraph - our current version is 2.6.3.2
2. Install pythia and delphes within Madgraph
3. Put madgraph_*_commands.py and the cards (*.dat) in the madgraph/bin directory
4. To generate SM files, use madgraph_SM_commands.py, instructions on usage are in the file
5. To generate SUSY files, use madgraph_SUSY_commands.py, instructions on usage are in the file
5a. For SUSY SLHA files, one needs to convert standard SLHA to SLHA2. Conversion file is in directory UTILITIES. Examples of converted files are in SLHA_CONVERTED_EXAMPLES. The original SLHA files are also in that directory.
6. Once root files are generated, convert to CSV with file convert_csv.cc in the UTILITIES directory. 
This requires root to be installed. Instructions on usage are in the file convert_csv.cc.
It creates CSV files with variable line lengths (see below). If this is unwanted, use fixed_length.py to create a csv file with a fixed object length. Instructions on this file are in fixed_length.py (in dir UTILITIES). 

The format of CSV files are:
event weight; MET; METphi; object1, pt1, eta1, phi1; object2, pt2, etc.
The object types are j (jet) b (bjet) e- (electron) e+ (positron) mu- (muon) mu+ (antimuon) a (photon).  
The event weight is defined as total xsec/#generated events in a single run. So if you use several runs (separated by the ==== lines), also divide by the number of runs you have used to make the weights add up to the total xsec. 

------------------

Note that xsec*luminosity = # events. So to know how many events one needs to take from each signal file, one needs to add them with the correct weight. A simple pseudocode that does this for you would be:

out = commands.getoutput("ls *") #location of your files
out = out.split()
lumni = 30 #lumni in fb (input!)
# array to store selection of background types (relevant for the analysis) with xsec in pb:
backtypes = {'4top':('p_p_to_t_t~_t_t~',0.0096),'single_top':("p_p_to_t_j",130),'single_topbar':("p_p_to_t~_j",111.5),'ttbarGam':("p_p_to_t_t~_a",1.547),'ttbarHiggs':("p_p_to_t_t~_h",0.46),'ttbar':('p_p_to_t_t~_2',532.7),'ttbarW':("p_p_to_t_t~_w_0",0.35),'ttbarWW':("p_p_to_t_t~_w_w",0.0085),'ttbarZ':("p_p_to_t_t~_z",0.59),'wtopbar':("p_p_to_t~_w_2",319.58),'wtop':("p_p_to_t_w_2",320)}
for key, values in backtypes.items():
        backtypes.update({key:(values[0],values[1],int(1000*values[1]*lumni))})

#way to select data, very simple and not sufficient snippet, one can rewrite this to their own needs
i = 0
arrayofarray = []
for key, values in backtypes.items():
        nlines = []
        for files in out:
                if values[0] in files:
                        txt = open(files)
                        for line in txt:
                                if i < values[2]:
                                        nlines.append(line)
                                        i += 1
                                else:
                                        break
                        if i < values[2]:
                                break
        arrayofarray.append(nlines)

-------------------------------------
